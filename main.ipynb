{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a6562c",
   "metadata": {},
   "source": [
    "# Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b7e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, function_tool\n",
    "from agents.run import RunConfig\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError('Gemini API Key is not valid.')\n",
    "\n",
    "\n",
    "external_client = AsyncOpenAI(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "model = OpenAIChatCompletionsModel(\n",
    "    model='gemini-2.0-flash',\n",
    "    openai_client=external_client\n",
    ")\n",
    "\n",
    "config = RunConfig(\n",
    "    model=model,\n",
    "    model_provider=external_client,\n",
    "    tracing_disabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7b9b1",
   "metadata": {},
   "source": [
    "## Tool raising error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8e8948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divide tool called\n",
      "I am sorry, I cannot perform this calculation at this time. Please try again later.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@function_tool\n",
    "def divide(a: float, b: float) -> float:\n",
    "    '''\n",
    "    Performs division between two numbers\n",
    "\n",
    "    Args:\n",
    "        a: dividend\n",
    "        b: diviser\n",
    "    '''\n",
    "\n",
    "    print('divide tool called')\n",
    "    # return a / b\n",
    "    raise ValueError('Not Good values')\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name='Supportive Agent',\n",
    "    instructions='Give helpful and concise answers',\n",
    "    model=model,\n",
    "    tools=[divide]\n",
    ")\n",
    "\n",
    "res = await Runner.run(agent, 'What is 8/2?', run_config=config)\n",
    "print(res.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e3efe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divide tool called\n",
      "I am unable to calculate this at the moment. Please try again later.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@function_tool\n",
    "def divide(a: float, b: float) -> float:\n",
    "    '''\n",
    "    Performs division between two numbers\n",
    "\n",
    "    Args:\n",
    "        a: dividend\n",
    "        b: diviser\n",
    "    '''\n",
    "    print('divide tool called')\n",
    "    try:\n",
    "        raise ZeroDivisionError(\"manual error for test\")\n",
    "        return a / b\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Error during division: {e}')\n",
    "\n",
    "agent2 = Agent(\n",
    "    name='Supportive Agent',\n",
    "    instructions='Must Use tool to answer',\n",
    "    model=model,\n",
    "    tools=[divide]\n",
    ")\n",
    "\n",
    "res = await Runner.run(agent2, 'What is 8/4', run_config=config)\n",
    "print(res.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ada92",
   "metadata": {},
   "source": [
    "## Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2486f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN HOOK] Starting agent: EchoAgent\n",
      "[AGENT HOOK] EchoAgent started\n",
      "[RUN HOOK] Agent 'EchoAgent' is invoking tool: echo_tool\n",
      "[AGENT HOOK] EchoAgent is about to call echo_tool\n",
      "[RUN HOOK] Tool 'echo_tool' returned: ECHO: Hello, world!\n",
      "[AGENT HOOK] EchoAgent got tool result: ECHO: Hello, world!\n",
      "[RUN HOOK] Agent 'EchoAgent' finished with output: Hello, world!\n",
      "\n",
      "[AGENT HOOK] EchoAgent ended with: Hello, world!\n",
      "\n",
      "Final answer: Hello, world!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agents.lifecycle import RunHooks, AgentHooks\n",
    "\n",
    "# Define a sample tool\n",
    "@function_tool\n",
    "def echo_tool(message: str) -> str:\n",
    "    \"\"\"Echoes the input message.\"\"\"\n",
    "    return f\"ECHO: {message}\"\n",
    "\n",
    "# Run-level hooks for all agent runs\n",
    "class MyRunHooks(RunHooks):\n",
    "    async def on_agent_start(self, context, agent):\n",
    "        print(f\"[RUN HOOK] Starting agent: {agent.name}\")\n",
    "\n",
    "    async def on_tool_start(self, context, agent, tool: Tool):\n",
    "        print(f\"[RUN HOOK] Agent '{agent.name}' is invoking tool: {tool.name}\")\n",
    "\n",
    "    async def on_tool_end(self, context, agent, tool, result: str):\n",
    "        print(f\"[RUN HOOK] Tool '{tool.name}' returned: {result}\")\n",
    "\n",
    "    async def on_agent_end(self, context, agent, output):\n",
    "        print(f\"[RUN HOOK] Agent '{agent.name}' finished with output: {output}\")\n",
    "\n",
    "# Agent-level hooks for one specific agent\n",
    "class MyAgentHooks(AgentHooks):\n",
    "    async def on_start(self, context, agent):\n",
    "        print(f\"[AGENT HOOK] {agent.name} started\")\n",
    "\n",
    "    async def on_tool_start(self, context, agent, tool: Tool):\n",
    "        print(f\"[AGENT HOOK] {agent.name} is about to call {tool.name}\")\n",
    "\n",
    "    async def on_tool_end(self, context, agent, tool, result: str):\n",
    "        print(f\"[AGENT HOOK] {agent.name} got tool result: {result}\")\n",
    "\n",
    "    async def on_end(self, context, agent, output):\n",
    "        print(f\"[AGENT HOOK] {agent.name} ended with: {output}\")\n",
    "\n",
    "# Create agent and attach hooks\n",
    "agent = Agent(\n",
    "    name=\"EchoAgent\",\n",
    "    instructions=\"Echo back your input using the echo_tool.\",\n",
    "    tools=[echo_tool],\n",
    "    model=model,\n",
    "    hooks=MyAgentHooks()\n",
    ")\n",
    "agent.hooks = MyAgentHooks()\n",
    "\n",
    "# Create runner with run-level hooks\n",
    "result = await Runner.run(agent, \"Hello, world!\", run_config=config, hooks=MyRunHooks())\n",
    "print(\"Final answer:\", result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f41bb6e",
   "metadata": {},
   "source": [
    "## Streaming with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "619d7b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, buckle up, buttercup! Here are 5 jokes ready to launch:\n",
      "\n",
      "1.  Why don't scientists trust atoms? Because they make up everything!\n",
      "\n",
      "2.  Parallel lines have so much in common. It's a shame they'll never meet.\n",
      "\n",
      "3.  Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "4.  I used to hate facial hair... but then it grew on me.\n",
      "\n",
      "5.  What concert costs just 45 cents? 50 Cent featuring Nickelback!\n",
      "\n",
      "Hope at least one of those tickled your funny bone!  Let me know if you want another round!\n"
     ]
    }
   ],
   "source": [
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "\n",
    "streaming_agent = Agent(\n",
    "    name=\"Joker\",\n",
    "    instructions=\"You are a joke telling assistant.\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "result = Runner.run_streamed(streaming_agent, input=\"Please tell me 5 jokes.\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
